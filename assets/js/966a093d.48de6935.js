"use strict";(self.webpackChunkhumanoid_robotics_book=self.webpackChunkhumanoid_robotics_book||[]).push([[4821],{28453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>a});var o=i(96540);const t={},s=o.createContext(t);function r(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),o.createElement(s.Provider,{value:e},n.children)}},54727:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-3-simulation-environments/unity-robotics-hub","title":"Chapter 3.2 - Unity Robotics Hub","description":"Game-Engine Based Simulation with Unity","source":"@site/docs/module-3-simulation-environments/unity-robotics-hub.mdx","sourceDirName":"module-3-simulation-environments","slug":"/module-3-simulation-environments/unity-robotics-hub","permalink":"/humanoid-robotics-book/docs/module-3-simulation-environments/unity-robotics-hub","draft":false,"unlisted":false,"editUrl":"https://github.com/ibrahimgem/humanoid-robotics-book/edit/main/docs/module-3-simulation-environments/unity-robotics-hub.mdx","tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"title":"Chapter 3.2 - Unity Robotics Hub","description":"Game-Engine Based Simulation with Unity"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3.1 - Gazebo Simulation for Humanoids","permalink":"/humanoid-robotics-book/docs/module-3-simulation-environments/gazebo-simulation-humanoids"},"next":{"title":"Chapter 3.3 - NVIDIA Isaac Sim","permalink":"/humanoid-robotics-book/docs/module-3-simulation-environments/nvidia-isaac-sim"}}');var t=i(74848),s=i(28453);const r={sidebar_position:12,title:"Chapter 3.2 - Unity Robotics Hub",description:"Game-Engine Based Simulation with Unity"},a="Chapter 3.2: Unity Robotics Hub",l={},c=[{value:"Goal",id:"goal",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Unity Robotics Hub Overview",id:"unity-robotics-hub-overview",level:2},{value:"Key Components",id:"key-components",level:3},{value:"Advantages of Unity for Robotics",id:"advantages-of-unity-for-robotics",level:3},{value:"Setting Up Unity Robotics Hub",id:"setting-up-unity-robotics-hub",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installation Process",id:"installation-process",level:3},{value:"Unity Package Installation",id:"unity-package-installation",level:3},{value:"Creating Humanoid Robot Models in Unity",id:"creating-humanoid-robot-models-in-unity",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Robot Setup in Unity",id:"robot-setup-in-unity",level:3},{value:"Joint Configuration",id:"joint-configuration",level:3},{value:"Sensor Integration in Unity",id:"sensor-integration-in-unity",level:2},{value:"Camera Sensors",id:"camera-sensors",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:3},{value:"ROS Communication in Unity",id:"ros-communication-in-unity",level:2},{value:"Setting Up ROS-TCP-Connector",id:"setting-up-ros-tcp-connector",level:3},{value:"Custom Message Types",id:"custom-message-types",level:3},{value:"Environment Creation for Humanoid Robots",id:"environment-creation-for-humanoid-robots",level:2},{value:"Scene Setup",id:"scene-setup",level:3},{value:"Procedural Environment Generation",id:"procedural-environment-generation",level:3},{value:"Dynamic Environment Elements",id:"dynamic-environment-elements",level:3},{value:"Physics and Animation for Humanoids",id:"physics-and-animation-for-humanoids",level:2},{value:"Character Controller vs Rigidbody",id:"character-controller-vs-rigidbody",level:3},{value:"Animation Integration",id:"animation-integration",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Level of Detail (LOD)",id:"level-of-detail-lod",level:3},{value:"Sensor Performance",id:"sensor-performance",level:3},{value:"Best Practices for Unity Robotics",id:"best-practices-for-unity-robotics",level:2},{value:"Model Optimization",id:"model-optimization",level:3},{value:"Simulation Quality",id:"simulation-quality",level:3},{value:"Integration Considerations",id:"integration-considerations",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Coordinate System Mismatch",id:"coordinate-system-mismatch",level:3},{value:"Performance Issues",id:"performance-issues",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"References",id:"references",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-32-unity-robotics-hub",children:"Chapter 3.2: Unity Robotics Hub"})}),"\n",(0,t.jsx)(e.h2,{id:"goal",children:"Goal"}),"\n",(0,t.jsx)(e.p,{children:"Explore Unity as a simulation platform for humanoid robotics with high-quality rendering."}),"\n",(0,t.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,t.jsx)(e.p,{children:"After completing this chapter, students will implement humanoid robot simulation in Unity with sensor integration."}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Unity Robotics Hub represents a significant advancement in robotics simulation, leveraging Unity's powerful game engine capabilities for high-fidelity, photorealistic simulation. Unlike traditional physics simulators, Unity excels in visual rendering quality, making it ideal for computer vision tasks, perception system training, and human-robot interaction studies. The Unity Robotics Hub provides the tools and frameworks necessary to integrate Unity with ROS 2, enabling complex humanoid robotics simulation with unprecedented visual fidelity."}),"\n",(0,t.jsx)(e.h2,{id:"unity-robotics-hub-overview",children:"Unity Robotics Hub Overview"}),"\n",(0,t.jsx)(e.h3,{id:"key-components",children:"Key Components"}),"\n",(0,t.jsx)(e.p,{children:"The Unity Robotics Hub consists of several key components that facilitate robotics simulation:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Robot Framework"}),": Provides tools for creating and controlling robots in Unity"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": Enables communication between Unity and ROS 2"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Synthetic Data Tools"}),": Generate training data for perception systems"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Perception Tools"}),": Simulate various sensors including cameras, LIDAR, and depth sensors"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robotics Library"}),": Pre-built components for common robotics tasks"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"advantages-of-unity-for-robotics",children:"Advantages of Unity for Robotics"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"High-Quality Rendering"}),": Photorealistic graphics for computer vision training"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Flexible Environments"}),": Create diverse and complex scenarios"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Realistic Lighting"}),": Simulate various lighting conditions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Asset Store"}),": Access to thousands of 3D models and environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Cross-Platform"}),": Deploy to multiple platforms including VR/AR"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"setting-up-unity-robotics-hub",children:"Setting Up Unity Robotics Hub"}),"\n",(0,t.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(e.p,{children:"Before starting with Unity Robotics Hub, ensure you have:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Unity Hub and Unity 2021.3 LTS or later"}),"\n",(0,t.jsx)(e.li,{children:"Unity Robot Framework package"}),"\n",(0,t.jsx)(e.li,{children:"ROS-TCP-Connector"}),"\n",(0,t.jsx)(e.li,{children:"Python with ROS 2 environment"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"installation-process",children:"Installation Process"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Install Unity Hub"}),": Download from Unity's official website"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Install Unity"}),": Install version 2021.3 LTS or later"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Create New Project"}),": Create a 3D project for robotics simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Install Packages"}),": Add Unity Robotics packages through Package Manager"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"unity-package-installation",children:"Unity Package Installation"}),"\n",(0,t.jsx)(e.p,{children:"In Unity, navigate to Window > Package Manager and install:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS TCP Connector"}),": Enables communication with ROS 2"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robot Framework"}),": Provides robotics-specific components"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Perception Tools"}),": For sensor simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Synthetic Data"}),": For generating training data"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"creating-humanoid-robot-models-in-unity",children:"Creating Humanoid Robot Models in Unity"}),"\n",(0,t.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,t.jsx)(e.p,{children:"Unity supports various 3D model formats (FBX, OBJ, DAE). For humanoid robots, you can:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Convert URDF to Unity"}),": Use tools like the URDF Importer"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Import CAD Models"}),": Import models directly from CAD software"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Create Procedurally"}),": Build robots using Unity's tools"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"robot-setup-in-unity",children:"Robot Setup in Unity"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class HumanoidRobot : MonoBehaviour\n{\n    // Robot components\n    public Transform[] joints;\n    public Transform[] links;\n\n    // ROS communication\n    private ROSConnection ros;\n\n    // Joint control\n    private float[] jointPositions;\n    private float[] jointVelocities;\n\n    void Start()\n    {\n        // Initialize ROS connection\n        ros = ROSConnection.instance;\n\n        // Subscribe to joint commands\n        ros.Subscribe<sensor_msgs.JointState>("/joint_commands", JointCommandCallback);\n\n        // Initialize joint arrays\n        jointPositions = new float[joints.Length];\n        jointVelocities = new float[joints.Length];\n    }\n\n    void JointCommandCallback(JointState jointState)\n    {\n        // Process joint commands from ROS\n        for (int i = 0; i < jointState.name.Count; i++)\n        {\n            string jointName = jointState.name[i];\n            int jointIndex = FindJointIndex(jointName);\n\n            if (jointIndex >= 0)\n            {\n                jointPositions[jointIndex] = (float)jointState.position[i];\n                jointVelocities[jointIndex] = (float)jointState.velocity[i];\n            }\n        }\n    }\n\n    void Update()\n    {\n        // Update joint positions in Unity\n        for (int i = 0; i < joints.Length; i++)\n        {\n            // Apply joint position (simplified)\n            joints[i].localRotation = Quaternion.Euler(0, jointPositions[i] * Mathf.Rad2Deg, 0);\n        }\n    }\n\n    int FindJointIndex(string jointName)\n    {\n        // Find the index of a joint by name\n        for (int i = 0; i < joints.Length; i++)\n        {\n            if (joints[i].name == jointName)\n                return i;\n        }\n        return -1;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"joint-configuration",children:"Joint Configuration"}),"\n",(0,t.jsx)(e.p,{children:"For humanoid robots, proper joint configuration is crucial:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"using UnityEngine;\n\n[System.Serializable]\npublic class JointConfig\n{\n    public string jointName;\n    public Joint joint;\n    public float minAngle;\n    public float maxAngle;\n    public float maxVelocity;\n    public float maxEffort;\n}\n\npublic class HumanoidJointController : MonoBehaviour\n{\n    public JointConfig[] jointConfigs;\n\n    public void SetJointPosition(string jointName, float position)\n    {\n        JointConfig config = System.Array.Find(jointConfigs, j => j.jointName == jointName);\n        if (config != null)\n        {\n            // Clamp position to joint limits\n            position = Mathf.Clamp(position, config.minAngle, config.maxAngle);\n\n            // Apply position to joint\n            ConfigurableJoint configurableJoint = config.joint as ConfigurableJoint;\n            if (configurableJoint != null)\n            {\n                // Calculate target rotation\n                Quaternion targetRotation = Quaternion.Euler(0, position * Mathf.Rad2Deg, 0);\n                configurableJoint.targetRotation = targetRotation;\n            }\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(e.h2,{id:"sensor-integration-in-unity",children:"Sensor Integration in Unity"}),"\n",(0,t.jsx)(e.h3,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,t.jsx)(e.p,{children:"Unity's camera system can simulate various camera types:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class UnityCameraSensor : MonoBehaviour\n{\n    public Camera unityCamera;\n    public string topicName = "/camera/image_raw";\n    public int imageWidth = 640;\n    public int imageHeight = 480;\n    public float publishRate = 30.0f;\n\n    private RenderTexture renderTexture;\n    private Texture2D texture2D;\n    private ROSConnection ros;\n    private float lastPublishTime;\n\n    void Start()\n    {\n        // Initialize ROS connection\n        ros = ROSConnection.instance;\n\n        // Create render texture\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\n        unityCamera.targetTexture = renderTexture;\n\n        // Create texture for conversion\n        texture2D = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);\n\n        lastPublishTime = Time.time;\n    }\n\n    void Update()\n    {\n        // Check if it\'s time to publish\n        if (Time.time - lastPublishTime >= 1.0f / publishRate)\n        {\n            PublishCameraImage();\n            lastPublishTime = Time.time;\n        }\n    }\n\n    void PublishCameraImage()\n    {\n        // Copy render texture to regular texture\n        RenderTexture.active = renderTexture;\n        texture2D.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\n        texture2D.Apply();\n\n        // Convert to ROS message (simplified)\n        byte[] imageData = texture2D.EncodeToPNG();\n\n        // Publish to ROS (implementation depends on specific ROS-TCP-Connector usage)\n        // ros.Publish(topicName, imageMsg);\n    }\n\n    void OnDestroy()\n    {\n        if (renderTexture != null)\n            renderTexture.Release();\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Unity can simulate LIDAR sensors using raycasting:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class UnityLidarSensor : MonoBehaviour\n{\n    [Header("LIDAR Configuration")]\n    public int horizontalRays = 360;\n    public int verticalRays = 1;\n    public float minRange = 0.1f;\n    public float maxRange = 10.0f;\n    public float angleMin = -Mathf.PI;\n    public float angleMax = Mathf.PI;\n\n    [Header("Performance")]\n    public float updateRate = 10.0f;\n\n    private float lastUpdateTime;\n    private List<float> ranges;\n\n    void Start()\n    {\n        ranges = new List<float>(horizontalRays * verticalRays);\n        lastUpdateTime = Time.time;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= 1.0f / updateRate)\n        {\n            SimulateLidarScan();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    void SimulateLidarScan()\n    {\n        ranges.Clear();\n\n        for (int v = 0; v < verticalRays; v++)\n        {\n            float verticalAngle = Mathf.Lerp(-0.1f, 0.1f, (float)v / (verticalRays - 1));\n\n            for (int h = 0; h < horizontalRays; h++)\n            {\n                float horizontalAngle = Mathf.Lerp(angleMin, angleMax, (float)h / (horizontalRays - 1));\n\n                // Calculate ray direction\n                Vector3 direction = Quaternion.Euler(verticalAngle * Mathf.Rad2Deg,\n                                                   horizontalAngle * Mathf.Rad2Deg, 0) * transform.forward;\n\n                // Raycast\n                RaycastHit hit;\n                if (Physics.Raycast(transform.position, direction, out hit, maxRange))\n                {\n                    ranges.Add(hit.distance);\n                }\n                else\n                {\n                    ranges.Add(maxRange);\n                }\n            }\n        }\n    }\n\n    public float[] GetRanges()\n    {\n        return ranges.ToArray();\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Simulate IMU data using Unity's physics system:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class UnityImuSensor : MonoBehaviour\n{\n    public string topicName = "/imu/data";\n    public float noiseLevel = 0.01f;\n    public float publishRate = 100.0f;\n\n    private Rigidbody robotBody;\n    private ROSConnection ros;\n    private float lastPublishTime;\n\n    void Start()\n    {\n        ros = ROSConnection.instance;\n        robotBody = GetComponent<Rigidbody>();\n        lastPublishTime = Time.time;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastPublishTime >= 1.0f / publishRate)\n        {\n            PublishImuData();\n            lastPublishTime = Time.time;\n        }\n    }\n\n    void PublishImuData()\n    {\n        // Create IMU message (simplified structure)\n        Imu imuMsg = new Imu();\n\n        // Orientation from robot\'s rotation\n        Quaternion robotRotation = transform.rotation;\n        imuMsg.orientation.x = robotRotation.x;\n        imuMsg.orientation.y = robotRotation.y;\n        imuMsg.orientation.z = robotRotation.z;\n        imuMsg.orientation.w = robotRotation.w;\n\n        // Angular velocity from physics\n        Vector3 angularVelocity = robotBody.angularVelocity;\n        imuMsg.angular_velocity.x = angularVelocity.x + Random.Range(-noiseLevel, noiseLevel);\n        imuMsg.angular_velocity.y = angularVelocity.y + Random.Range(-noiseLevel, noiseLevel);\n        imuMsg.angular_velocity.z = angularVelocity.z + Random.Range(-noiseLevel, noiseLevel);\n\n        // Linear acceleration\n        Vector3 linearAcc = robotBody.velocity / Time.fixedDeltaTime;\n        imuMsg.linear_acceleration.x = linearAcc.x + Random.Range(-noiseLevel, noiseLevel);\n        imuMsg.linear_acceleration.y = linearAcc.y + Random.Range(-noiseLevel, noiseLevel);\n        imuMsg.linear_acceleration.z = linearAcc.z + Random.Range(-noiseLevel, noiseLevel);\n\n        // Publish to ROS\n        ros.Publish(topicName, imuMsg);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"ros-communication-in-unity",children:"ROS Communication in Unity"}),"\n",(0,t.jsx)(e.h3,{id:"setting-up-ros-tcp-connector",children:"Setting Up ROS-TCP-Connector"}),"\n",(0,t.jsx)(e.p,{children:"The ROS-TCP-Connector enables communication between Unity and ROS 2:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\n\npublic class UnityRosBridge : MonoBehaviour\n{\n    public string rosIPAddress = "127.0.0.1";\n    public int rosPort = 10000;\n\n    private ROSConnection ros;\n\n    void Start()\n    {\n        ros = ROSConnection.instance;\n\n        // Connect to ROS\n        ros.Initialize(rosIPAddress, rosPort);\n\n        // Subscribe to topics\n        ros.Subscribe<sensor_msgs.JointState>("/joint_states", OnJointStateReceived);\n        ros.Subscribe<geometry_msgs.Twist>("/cmd_vel", OnCmdVelReceived);\n\n        // Publish to topics\n        ros.RegisterPublisher<sensor_msgs.JointState>("/joint_commands");\n    }\n\n    void OnJointStateReceived(JointState jointState)\n    {\n        // Handle received joint states\n        Debug.Log($"Received joint state with {jointState.name.Count} joints");\n    }\n\n    void OnCmdVelReceived(geometry_msgs.Twist cmdVel)\n    {\n        // Handle velocity commands\n        Debug.Log($"Received velocity command: {cmdVel.linear.x}, {cmdVel.angular.z}");\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"custom-message-types",children:"Custom Message Types"}),"\n",(0,t.jsx)(e.p,{children:"For humanoid-specific messages, you can define custom message types:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector.MessageGeneration;\n\npublic class HumanoidState : Message\n{\n    public const string k_RosMessageName = "my_robot_msgs/HumanoidState";\n    public override string RosMessageName => k_RosMessageName;\n\n    public string[] joint_names;\n    public double[] positions;\n    public double[] velocities;\n    public double[] efforts;\n    public geometry_msgs.Pose center_of_mass;\n    public bool in_support;\n\n    public HumanoidState()\n    {\n        joint_names = new string[0];\n        positions = new double[0];\n        velocities = new double[0];\n        efforts = new double[0];\n        center_of_mass = new geometry_msgs.Pose();\n        in_support = false;\n    }\n\n    public HumanoidState(string[] jointNames, double[] positions, double[] velocities,\n                        double[] efforts, geometry_msgs.Pose com, bool inSupport)\n    {\n        this.joint_names = jointNames;\n        this.positions = positions;\n        this.velocities = velocities;\n        this.efforts = efforts;\n        this.center_of_mass = com;\n        this.in_support = inSupport;\n    }\n\n    public static HumanoidState Deserialize(MessageDeserializer deserializer)\n    {\n        var outMessage = new HumanoidState();\n        deserializer.Read(outMessage.joint_names);\n        deserializer.Read(outMessage.positions);\n        deserializer.Read(outMessage.velocities);\n        deserializer.Read(outMessage.efforts);\n        deserializer.Read(outMessage.center_of_mass);\n        deserializer.Read(outMessage.in_support);\n        return outMessage;\n    }\n\n    public override void SerializeTo(MessageSerializer serializer)\n    {\n        serializer.Write(this.joint_names);\n        serializer.Write(this.positions);\n        serializer.Write(this.velocities);\n        serializer.Write(this.efforts);\n        serializer.Write(this.center_of_mass);\n        serializer.Write(this.in_support);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"environment-creation-for-humanoid-robots",children:"Environment Creation for Humanoid Robots"}),"\n",(0,t.jsx)(e.h3,{id:"scene-setup",children:"Scene Setup"}),"\n",(0,t.jsx)(e.p,{children:"Creating appropriate environments for humanoid robots involves:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Navigation Spaces"}),": Ensure areas are navigable for bipedal locomotion"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Interaction Objects"}),": Place objects for manipulation tasks"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Lighting Conditions"}),": Vary lighting to test perception systems"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Terrain Types"}),": Include various surfaces for walking simulation"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"procedural-environment-generation",children:"Procedural Environment Generation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class HumanoidEnvironmentGenerator : MonoBehaviour\n{\n    public GameObject[] floorTiles;\n    public GameObject[] obstacles;\n    public GameObject[] interactionObjects;\n\n    [Header("Environment Parameters")]\n    public int gridSize = 10;\n    public float cellSize = 2.0f;\n    public float obstacleDensity = 0.1f;\n\n    void Start()\n    {\n        GenerateEnvironment();\n    }\n\n    void GenerateEnvironment()\n    {\n        // Create floor grid\n        for (int x = 0; x < gridSize; x++)\n        {\n            for (int z = 0; z < gridSize; z++)\n            {\n                Vector3 position = new Vector3(x * cellSize, 0, z * cellSize);\n\n                // Choose appropriate floor tile\n                int tileIndex = Random.Range(0, floorTiles.Length);\n                Instantiate(floorTiles[tileIndex], position, Quaternion.identity);\n\n                // Randomly place obstacles\n                if (Random.value < obstacleDensity)\n                {\n                    int obstacleIndex = Random.Range(0, obstacles.Length);\n                    Vector3 obstaclePos = position + new Vector3(0, 1, 0);\n                    Instantiate(obstacles[obstacleIndex], obstaclePos, Quaternion.identity);\n                }\n            }\n        }\n\n        // Place interaction objects\n        PlaceInteractionObjects();\n    }\n\n    void PlaceInteractionObjects()\n    {\n        // Place objects for humanoid interaction\n        for (int i = 0; i < 5; i++)\n        {\n            Vector3 randomPos = new Vector3(\n                Random.Range(2, gridSize * cellSize - 2),\n                1.0f,\n                Random.Range(2, gridSize * cellSize - 2)\n            );\n\n            int objIndex = Random.Range(0, interactionObjects.Length);\n            Instantiate(interactionObjects[objIndex], randomPos, Quaternion.identity);\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"dynamic-environment-elements",children:"Dynamic Environment Elements"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class DynamicEnvironmentElement : MonoBehaviour\n{\n    [Header("Movement Configuration")]\n    public bool isMovable = true;\n    public Vector3 movementRange = new Vector3(1, 0, 1);\n    public float movementSpeed = 1.0f;\n\n    [Header("Interaction Configuration")]\n    public bool canBeGrasped = true;\n    public float mass = 1.0f;\n\n    private Vector3 initialPosition;\n    private Vector3 targetPosition;\n    private Rigidbody rb;\n\n    void Start()\n    {\n        initialPosition = transform.position;\n        rb = GetComponent<Rigidbody>();\n\n        if (rb != null)\n        {\n            rb.mass = mass;\n        }\n\n        SetNewTarget();\n    }\n\n    void Update()\n    {\n        if (isMovable)\n        {\n            MoveTowardsTarget();\n        }\n    }\n\n    void MoveTowardsTarget()\n    {\n        transform.position = Vector3.MoveTowards(\n            transform.position,\n            targetPosition,\n            movementSpeed * Time.deltaTime\n        );\n\n        // Check if reached target\n        if (Vector3.Distance(transform.position, targetPosition) < 0.1f)\n        {\n            SetNewTarget();\n        }\n    }\n\n    void SetNewTarget()\n    {\n        Vector3 randomOffset = new Vector3(\n            Random.Range(-movementRange.x, movementRange.x),\n            Random.Range(-movementRange.y, movementRange.y),\n            Random.Range(-movementRange.z, movementRange.z)\n        );\n\n        targetPosition = initialPosition + randomOffset;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"physics-and-animation-for-humanoids",children:"Physics and Animation for Humanoids"}),"\n",(0,t.jsx)(e.h3,{id:"character-controller-vs-rigidbody",children:"Character Controller vs Rigidbody"}),"\n",(0,t.jsx)(e.p,{children:"For humanoid robots, you can use either Unity's CharacterController or Rigidbody:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class HumanoidLocomotion : MonoBehaviour\n{\n    public float walkSpeed = 2.0f;\n    public float runSpeed = 4.0f;\n    public float jumpForce = 8.0f;\n\n    private CharacterController controller;\n    private Vector3 velocity;\n    private bool isGrounded;\n\n    void Start()\n    {\n        controller = GetComponent<CharacterController>();\n    }\n\n    void Update()\n    {\n        // Check if grounded\n        isGrounded = controller.isGrounded;\n        if (isGrounded && velocity.y < 0)\n        {\n            velocity.y = -2f;\n        }\n\n        // Movement input\n        float moveX = Input.GetAxis("Horizontal");\n        float moveZ = Input.GetAxis("Vertical");\n\n        Vector3 move = transform.right * moveX + transform.forward * moveZ;\n\n        // Apply movement\n        controller.Move(move * walkSpeed * Time.deltaTime);\n\n        // Apply gravity\n        velocity.y += Physics.gravity.y * Time.deltaTime;\n        controller.Move(velocity * Time.deltaTime);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"animation-integration",children:"Animation Integration"}),"\n",(0,t.jsx)(e.p,{children:"For more realistic humanoid movement, integrate with Unity's animation system:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\n\npublic class HumanoidAnimatorController : MonoBehaviour\n{\n    public Animator animator;\n    public float walkSpeedThreshold = 0.1f;\n    public float runSpeedThreshold = 2.0f;\n\n    [Header("Animation Parameters")]\n    public string speedParameter = "Speed";\n    public string directionParameter = "Direction";\n    public string jumpParameter = "IsJumping";\n\n    private Rigidbody rb;\n\n    void Start()\n    {\n        rb = GetComponent<Rigidbody>();\n        animator = GetComponent<Animator>();\n    }\n\n    void Update()\n    {\n        if (animator != null && rb != null)\n        {\n            // Calculate movement parameters\n            float speed = rb.velocity.magnitude;\n            Vector3 localVelocity = transform.InverseTransformDirection(rb.velocity);\n\n            // Update animation parameters\n            animator.SetFloat(speedParameter, speed);\n            animator.SetFloat(directionParameter, localVelocity.x);\n            animator.SetBool(jumpParameter, !IsGrounded());\n        }\n    }\n\n    bool IsGrounded()\n    {\n        // Check if the humanoid is grounded\n        return Physics.Raycast(transform.position, Vector3.down, 0.1f);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"level-of-detail-lod",children:"Level of Detail (LOD)"}),"\n",(0,t.jsx)(e.p,{children:"For complex humanoid robots, implement LOD systems:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"using UnityEngine;\n\npublic class HumanoidLODController : MonoBehaviour\n{\n    public GameObject[] lodGroups;\n    public float[] lodDistances;\n\n    private Transform viewer;\n\n    void Start()\n    {\n        viewer = Camera.main.transform;\n    }\n\n    void Update()\n    {\n        float distance = Vector3.Distance(viewer.position, transform.position);\n\n        for (int i = 0; i < lodDistances.Length; i++)\n        {\n            if (distance <= lodDistances[i])\n            {\n                ActivateLOD(i);\n                return;\n            }\n        }\n\n        // Activate lowest detail if too far\n        ActivateLOD(lodGroups.Length - 1);\n    }\n\n    void ActivateLOD(int lodIndex)\n    {\n        for (int i = 0; i < lodGroups.Length; i++)\n        {\n            lodGroups[i].SetActive(i == lodIndex);\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(e.h3,{id:"sensor-performance",children:"Sensor Performance"}),"\n",(0,t.jsx)(e.p,{children:"Optimize sensor simulation for real-time performance:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections;\n\npublic class OptimizedSensorController : MonoBehaviour\n{\n    [Header("Performance Settings")]\n    public float simulationRate = 30.0f;  // Lower rate for better performance\n    public bool useThreading = false;\n\n    private WaitForSeconds waitTime;\n    private Coroutine sensorCoroutine;\n\n    void Start()\n    {\n        waitTime = new WaitForSeconds(1.0f / simulationRate);\n        sensorCoroutine = StartCoroutine(SimulateSensors());\n    }\n\n    IEnumerator SimulateSensors()\n    {\n        while (true)\n        {\n            // Simulate all sensors\n            SimulateCameras();\n            SimulateLidar();\n            SimulateIMU();\n\n            yield return waitTime;\n        }\n    }\n\n    void SimulateCameras()\n    {\n        // Simulate camera sensors at reduced frequency\n    }\n\n    void SimulateLidar()\n    {\n        // Simulate LIDAR at reduced resolution\n    }\n\n    void SimulateIMU()\n    {\n        // Simulate IMU data\n    }\n\n    void OnDisable()\n    {\n        if (sensorCoroutine != null)\n        {\n            StopCoroutine(sensorCoroutine);\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices-for-unity-robotics",children:"Best Practices for Unity Robotics"}),"\n",(0,t.jsx)(e.h3,{id:"model-optimization",children:"Model Optimization"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use appropriate polygon counts for real-time simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement efficient collision meshes"}),"\n",(0,t.jsx)(e.li,{children:"Use texture atlasing for better performance"}),"\n",(0,t.jsx)(e.li,{children:"Optimize animation rigs for humanoid robots"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"simulation-quality",children:"Simulation Quality"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Use appropriate physics settings for humanoid dynamics"}),"\n",(0,t.jsx)(e.li,{children:"Implement proper sensor noise models"}),"\n",(0,t.jsx)(e.li,{children:"Validate simulation against real-world data"}),"\n",(0,t.jsx)(e.li,{children:"Test with various environmental conditions"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"integration-considerations",children:"Integration Considerations"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Ensure consistent coordinate systems between Unity and ROS"}),"\n",(0,t.jsx)(e.li,{children:"Implement proper time synchronization"}),"\n",(0,t.jsx)(e.li,{children:"Handle network latency in ROS communication"}),"\n",(0,t.jsx)(e.li,{children:"Use appropriate message rates for real-time performance"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(e.h3,{id:"coordinate-system-mismatch",children:"Coordinate System Mismatch"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"// Unity uses left-handed coordinate system, ROS uses right-handed\nVector3 RosToUnity(Vector3 rosVector)\n{\n    return new Vector3(rosVector.x, rosVector.z, rosVector.y);\n}\n\nVector3 UnityToRos(Vector3 unityVector)\n{\n    return new Vector3(unityVector.x, unityVector.z, unityVector.y);\n}\n"})}),"\n",(0,t.jsx)(e.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Reduce sensor update rates if needed"}),"\n",(0,t.jsx)(e.li,{children:"Use simplified collision meshes"}),"\n",(0,t.jsx)(e.li,{children:"Implement occlusion culling"}),"\n",(0,t.jsx)(e.li,{children:"Optimize material and shader complexity"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Unity Robotics Hub provides a powerful platform for high-quality humanoid robot simulation with photorealistic rendering capabilities. The combination of Unity's advanced graphics engine with ROS integration enables new possibilities for perception system training, human-robot interaction studies, and computer vision applications. Proper implementation of sensors, physics, and communication systems is essential for effective humanoid robot simulation in Unity."}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a humanoid robot model in Unity with proper joint configuration"}),"\n",(0,t.jsx)(e.li,{children:"Implement camera and IMU sensors with ROS communication"}),"\n",(0,t.jsx)(e.li,{children:"Build an environment suitable for humanoid navigation and interaction"}),"\n",(0,t.jsx)(e.li,{children:"Optimize your simulation for real-time performance"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"references",children:"References"}),"\n",(0,t.jsx)(e.p,{children:'[1] Unity Technologies, "Unity Robotics Hub Documentation," Unity Technologies, 2023.'}),"\n",(0,t.jsx)(e.p,{children:'[2] S. James et al., "PyBullet: A Real-time Robot Simulation Framework," Conference on Robot Learning, 2017.'}),"\n",(0,t.jsx)(e.p,{children:'[3] J. Tremblay et al., "Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations," ICRA, 2018.'})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}}}]);