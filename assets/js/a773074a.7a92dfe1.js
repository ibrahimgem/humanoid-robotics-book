"use strict";(self.webpackChunkhumanoid_robotics_book=self.webpackChunkhumanoid_robotics_book||[]).push([[9267],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var r=t(96540);const i={},a=r.createContext(i);function o(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(a.Provider,{value:n},e.children)}},47621:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"module-3-simulation-environments/simulation-to-real-transfer","title":"Chapter 3.4 - Simulation-to-Real Transfer","description":"Bridging Simulation and Reality","source":"@site/docs/module-3-simulation-environments/simulation-to-real-transfer.mdx","sourceDirName":"module-3-simulation-environments","slug":"/module-3-simulation-environments/simulation-to-real-transfer","permalink":"/humanoid-robotics-book/docs/module-3-simulation-environments/simulation-to-real-transfer","draft":false,"unlisted":false,"editUrl":"https://github.com/ibrahimgem/humanoid-robotics-book/edit/main/docs/module-3-simulation-environments/simulation-to-real-transfer.mdx","tags":[],"version":"current","sidebarPosition":14,"frontMatter":{"sidebar_position":14,"title":"Chapter 3.4 - Simulation-to-Real Transfer","description":"Bridging Simulation and Reality"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3.3 - NVIDIA Isaac Sim","permalink":"/humanoid-robotics-book/docs/module-3-simulation-environments/nvidia-isaac-sim"},"next":{"title":"Module 4 - NVIDIA Isaac Platform","permalink":"/humanoid-robotics-book/docs/category/module-4---nvidia-isaac-platform"}}');var i=t(74848),a=t(28453);const o={sidebar_position:14,title:"Chapter 3.4 - Simulation-to-Real Transfer",description:"Bridging Simulation and Reality"},s="Chapter 3.4: Simulation-to-Real Transfer",l={},d=[{value:"Goal",id:"goal",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Understanding the Reality Gap",id:"understanding-the-reality-gap",level:2},{value:"Sources of the Reality Gap",id:"sources-of-the-reality-gap",level:3},{value:"Physical Differences",id:"physical-differences",level:4},{value:"Sensor Differences",id:"sensor-differences",level:4},{value:"Environmental Differences",id:"environmental-differences",level:4},{value:"Quantifying the Reality Gap",id:"quantifying-the-reality-gap",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Basic Domain Randomization",id:"basic-domain-randomization",level:3},{value:"Advanced Domain Randomization Techniques",id:"advanced-domain-randomization-techniques",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"Parameter Estimation",id:"parameter-estimation",level:3},{value:"Model Fitting Techniques",id:"model-fitting-techniques",level:3},{value:"Robust Control Design",id:"robust-control-design",level:2},{value:"Robust PID Control",id:"robust-pid-control",level:3},{value:"Disturbance Observer",id:"disturbance-observer",level:3},{value:"Adaptive Control Techniques",id:"adaptive-control-techniques",level:2},{value:"Model Reference Adaptive Control (MRAC)",id:"model-reference-adaptive-control-mrac",level:3},{value:"Transfer Learning Strategies",id:"transfer-learning-strategies",level:2},{value:"Progressive Domain Transfer",id:"progressive-domain-transfer",level:3},{value:"Fine-tuning on Real Data",id:"fine-tuning-on-real-data",level:3},{value:"Evaluation and Validation",id:"evaluation-and-validation",level:2},{value:"Sim-to-Real Performance Metrics",id:"sim-to-real-performance-metrics",level:3},{value:"Best Practices for Sim-to-Real Transfer",id:"best-practices-for-sim-to-real-transfer",level:2},{value:"Pre-Transfer Validation",id:"pre-transfer-validation",level:3},{value:"Safety Considerations",id:"safety-considerations",level:3},{value:"Gradual Deployment",id:"gradual-deployment",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Poor Transfer Performance",id:"poor-transfer-performance",level:3},{value:"Instability on Real Robot",id:"instability-on-real-robot",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"References",id:"references",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-34-simulation-to-real-transfer",children:"Chapter 3.4: Simulation-to-Real Transfer"})}),"\n",(0,i.jsx)(n.h2,{id:"goal",children:"Goal"}),"\n",(0,i.jsx)(n.p,{children:"Understand techniques for transferring learned behaviors from simulation to real robots."}),"\n",(0,i.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(n.p,{children:"After completing this chapter, students will implement domain randomization and other techniques for sim-to-real transfer."}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:'Simulation-to-real transfer, often called "sim-to-real," is one of the most challenging aspects of robotics research. The goal is to develop behaviors, controllers, or learning algorithms in simulation that will work effectively on real robots. This is particularly challenging for humanoid robots due to their complex dynamics, numerous degrees of freedom, and sensitivity to environmental conditions. The "reality gap" between simulation and reality encompasses differences in physics, sensors, actuators, and environmental conditions that can cause behaviors learned in simulation to fail when deployed on real hardware.'}),"\n",(0,i.jsx)(n.h2,{id:"understanding-the-reality-gap",children:"Understanding the Reality Gap"}),"\n",(0,i.jsx)(n.h3,{id:"sources-of-the-reality-gap",children:"Sources of the Reality Gap"}),"\n",(0,i.jsx)(n.p,{children:"The reality gap arises from multiple sources that create differences between simulation and reality:"}),"\n",(0,i.jsx)(n.h4,{id:"physical-differences",children:"Physical Differences"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Inertial Properties"}),": Mass, center of mass, and moments of inertia may differ between model and reality"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Joint Friction"}),": Real joints have complex friction behaviors not fully captured in simulation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actuator Dynamics"}),": Real actuators have delays, bandwidth limitations, and non-linear responses"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexibility"}),": Real robots have structural flexibility not modeled in rigid-body simulation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Contact Mechanics"}),": Real contacts involve complex interactions not fully captured by simulation models"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"sensor-differences",children:"Sensor Differences"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Noise Characteristics"}),": Real sensors have different noise patterns than simulated ones"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Latency"}),": Real sensors often have processing and communication delays"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Calibration Errors"}),": Real sensors may have calibration errors not present in simulation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Environmental Effects"}),": Real sensors are affected by lighting, temperature, and other environmental factors"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"environmental-differences",children:"Environmental Differences"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Surface Properties"}),": Real surfaces have different friction, compliance, and texture than simulated ones"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"External Disturbances"}),": Real environments have unpredictable disturbances (wind, vibrations, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Modeling Limitations"}),": Perfect environment models are impossible to create"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"quantifying-the-reality-gap",children:"Quantifying the Reality Gap"}),"\n",(0,i.jsx)(n.p,{children:"Understanding and quantifying the reality gap is essential for successful sim-to-real transfer:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.transform import Rotation as R\n\nclass RealityGapAnalyzer:\n    def __init__(self, robot_model, real_robot_interface):\n        self.robot_model = robot_model\n        self.real_robot = real_robot_interface\n\n    def compare_kinematics(self, joint_angles):\n        """Compare forward kinematics between model and real robot"""\n        # Get end-effector pose from simulation\n        sim_pose = self.robot_model.forward_kinematics(joint_angles)\n\n        # Get end-effector pose from real robot\n        real_pose = self.real_robot.get_end_effector_pose()\n\n        # Calculate position error\n        pos_error = np.linalg.norm(sim_pose[:3] - real_pose[:3])\n\n        # Calculate orientation error\n        sim_rot = R.from_matrix(sim_pose[3:].reshape(3,3))\n        real_rot = R.from_matrix(real_pose[3:].reshape(3,3))\n        rot_error = np.abs(sim_rot.inv() * real_rot).as_rotvec()\n\n        return pos_error, rot_error\n\n    def analyze_dynamics(self, joint_commands, dt=0.01):\n        """Analyze dynamic response differences"""\n        # Apply same commands to simulation and real robot\n        sim_response = self.robot_model.simulate_dynamics(joint_commands, dt)\n        real_response = self.real_robot.execute_commands(joint_commands, dt)\n\n        # Compare joint positions, velocities, and accelerations\n        pos_diff = np.abs(sim_response[\'positions\'] - real_response[\'positions\'])\n        vel_diff = np.abs(sim_response[\'velocities\'] - real_response[\'velocities\'])\n\n        return pos_diff, vel_diff\n\n    def characterize_sensor_noise(self, num_samples=1000):\n        """Characterize real sensor noise patterns"""\n        sensor_data = []\n        for _ in range(num_samples):\n            data = self.real_robot.get_sensor_data()\n            sensor_data.append(data)\n\n        # Calculate statistics\n        sensor_mean = np.mean(sensor_data, axis=0)\n        sensor_std = np.std(sensor_data, axis=0)\n\n        return sensor_mean, sensor_std\n'})}),"\n",(0,i.jsx)(n.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,i.jsx)(n.p,{children:"Domain randomization is a key technique for improving sim-to-real transfer by training policies in diverse simulation environments."}),"\n",(0,i.jsx)(n.h3,{id:"basic-domain-randomization",children:"Basic Domain Randomization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport random\n\nclass DomainRandomizer:\n    def __init__(self):\n        self.randomization_params = {}\n\n    def add_randomization(self, param_name, min_val, max_val, randomization_type='uniform'):\n        \"\"\"Add a parameter to be randomized\"\"\"\n        self.randomization_params[param_name] = {\n            'min': min_val,\n            'max': max_val,\n            'type': randomization_type\n        }\n\n    def randomize_robot_properties(self, robot):\n        \"\"\"Randomize robot properties for domain randomization\"\"\"\n        # Randomize link masses\n        for i, link in enumerate(robot.links):\n            if random.random() < 0.5:  # Randomize 50% of the time\n                mass_factor = np.random.uniform(0.8, 1.2)  # \xb120% variation\n                robot.set_link_mass(i, link.mass * mass_factor)\n\n        # Randomize joint friction\n        for i, joint in enumerate(robot.joints):\n            friction = np.random.uniform(0.0, 0.1)  # Random friction\n            robot.set_joint_friction(i, friction)\n\n        # Randomize COM offsets\n        for i, link in enumerate(robot.links):\n            com_offset = np.random.uniform(-0.01, 0.01, 3)  # \xb11cm COM offset\n            robot.set_link_com_offset(i, com_offset)\n\n    def randomize_environment(self, env):\n        \"\"\"Randomize environment properties\"\"\"\n        # Randomize floor friction\n        floor_friction = np.random.uniform(0.4, 1.0)\n        env.set_floor_friction(floor_friction)\n\n        # Randomize lighting conditions\n        light_intensity = np.random.uniform(500, 2000)\n        env.set_light_intensity(light_intensity)\n\n        # Randomize object properties\n        for obj in env.objects:\n            if hasattr(obj, 'mass'):\n                mass_factor = np.random.uniform(0.8, 1.2)\n                obj.mass *= mass_factor\n\n    def randomize_sensors(self, robot):\n        \"\"\"Randomize sensor properties\"\"\"\n        # Randomize IMU noise parameters\n        for sensor in robot.imu_sensors:\n            sensor.noise_params['accelerometer']['std'] = np.random.uniform(0.001, 0.01)\n            sensor.noise_params['gyroscope']['std'] = np.random.uniform(0.0001, 0.001)\n\n        # Randomize camera parameters\n        for camera in robot.cameras:\n            camera.noise_std = np.random.uniform(0.01, 0.05)\n            camera.bias = np.random.uniform(-0.01, 0.01, 3)\n\n# Example usage\ndef setup_domain_randomization():\n    randomizer = DomainRandomizer()\n\n    # Add randomization for key parameters\n    randomizer.add_randomization('robot_mass', 0.8, 1.2, 'uniform')\n    randomizer.add_randomization('floor_friction', 0.4, 1.0, 'uniform')\n    randomizer.add_randomization('imu_noise', 0.001, 0.01, 'uniform')\n\n    return randomizer\n"})}),"\n",(0,i.jsx)(n.h3,{id:"advanced-domain-randomization-techniques",children:"Advanced Domain Randomization Techniques"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class AdvancedDomainRandomizer:\n    def __init__(self):\n        self.param_distributions = {}\n        self.randomization_schedule = {}\n\n    def setup_systematic_randomization(self):\n        \"\"\"Setup systematic parameter randomization\"\"\"\n        # Define parameter ranges with more sophisticated distributions\n        self.param_distributions = {\n            'link_mass_factor': {\n                'type': 'gaussian',\n                'mean': 1.0,\n                'std': 0.1,\n                'min': 0.7,\n                'max': 1.3\n            },\n            'joint_damping': {\n                'type': 'uniform',\n                'min': 0.01,\n                'max': 0.2\n            },\n            'imu_drift_rate': {\n                'type': 'gaussian',\n                'mean': 0.0,\n                'std': 0.001\n            },\n            'actuator_delay': {\n                'type': 'uniform',\n                'min': 0.0,\n                'max': 0.02  # 20ms delay\n            }\n        }\n\n    def apply_correlated_randomization(self, robot):\n        \"\"\"Apply correlated parameter randomization\"\"\"\n        # Randomize parameters that are physically related\n        base_mass_factor = np.random.normal(1.0, 0.1)\n\n        # Apply correlated mass factors (heavier robots tend to have heavier components)\n        for i, link in enumerate(robot.links):\n            # Correlate with base mass but add some independent variation\n            link_factor = base_mass_factor * np.random.uniform(0.9, 1.1)\n            link_factor = np.clip(link_factor, 0.7, 1.3)\n            robot.set_link_mass(i, link.mass * link_factor)\n\n    def temporal_randomization(self):\n        \"\"\"Apply time-varying randomization parameters\"\"\"\n        # Parameters that change over time during training\n        current_time = self.get_simulation_time()\n\n        # Slowly varying parameters\n        mass_drift = 0.01 * np.sin(current_time * 0.01)  # Slow drift\n        friction_drift = 0.05 * np.sin(current_time * 0.02)\n\n        return mass_drift, friction_drift\n\n    def adaptive_randomization(self, performance_history):\n        \"\"\"Adapt randomization based on learning progress\"\"\"\n        if len(performance_history) < 10:\n            return  # Not enough data yet\n\n        # Calculate recent performance trend\n        recent_perf = np.mean(performance_history[-10:])\n        overall_perf = np.mean(performance_history)\n\n        # Increase randomization if performance is plateauing\n        if abs(recent_perf - overall_perf) < 0.01:  # Performance plateau\n            self.increase_randomization_range()\n        elif recent_perf > overall_perf:  # Improving performance\n            self.maintain_randomization_range()\n\n    def increase_randomization_range(self):\n        \"\"\"Increase the range of randomization parameters\"\"\"\n        for param_name, config in self.param_distributions.items():\n            if 'range_multiplier' not in config:\n                config['range_multiplier'] = 1.0\n\n            config['range_multiplier'] = min(config['range_multiplier'] * 1.1, 2.0)\n\n    def setup_randomization_schedule(self):\n        \"\"\"Setup schedule for gradually increasing randomization\"\"\"\n        # Phase 1: Low randomization for initial learning\n        # Phase 2: Medium randomization for robustness\n        # Phase 3: High randomization for real-world readiness\n        self.randomization_schedule = {\n            'phase_1': {'duration': 100000, 'multiplier': 0.5},\n            'phase_2': {'duration': 200000, 'multiplier': 1.0},\n            'phase_3': {'duration': 300000, 'multiplier': 1.5}\n        }\n"})}),"\n",(0,i.jsx)(n.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,i.jsx)(n.p,{children:"System identification is crucial for creating accurate simulation models that match real robot behavior."}),"\n",(0,i.jsx)(n.h3,{id:"parameter-estimation",children:"Parameter Estimation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.integrate import solve_ivp\n\nclass SystemIdentifier:\n    def __init__(self, robot_model):\n        self.model = robot_model\n        self.identification_data = []\n\n    def collect_identification_data(self, robot, excitation_signals):\n        \"\"\"Collect data for system identification\"\"\"\n        for signal in excitation_signals:\n            # Apply excitation signal to robot\n            robot.apply_excitation(signal)\n\n            # Record inputs and outputs\n            input_data = signal.get_inputs()\n            output_data = robot.get_sensor_readings()\n\n            self.identification_data.append({\n                'inputs': input_data,\n                'outputs': output_data,\n                'timestamps': signal.get_timestamps()\n            })\n\n    def estimate_inertial_parameters(self):\n        \"\"\"Estimate inertial parameters using collected data\"\"\"\n        # Define objective function to minimize\n        def objective_function(params):\n            # Set model parameters\n            self.model.set_inertial_params(params)\n\n            total_error = 0\n            for data in self.identification_data:\n                # Simulate with current parameters\n                sim_outputs = self.model.simulate(data['inputs'])\n\n                # Calculate error\n                error = np.sum((sim_outputs - data['outputs'])**2)\n                total_error += error\n\n            return total_error\n\n        # Initial parameter guess\n        initial_params = self.model.get_current_inertial_params()\n\n        # Optimize parameters\n        result = minimize(objective_function, initial_params, method='BFGS')\n\n        # Update model with optimized parameters\n        self.model.set_inertial_params(result.x)\n\n        return result.x\n\n    def estimate_friction_parameters(self):\n        \"\"\"Estimate joint friction parameters\"\"\"\n        # Use Coulomb + viscous friction model: tau_friction = tau_static * sign(w) + b * w\n        friction_params = {}\n\n        for joint_idx in range(self.model.num_joints):\n            # Extract data for this joint\n            joint_data = self.extract_joint_data(joint_idx)\n\n            # Separate static and viscous friction\n            velocities = joint_data['velocities']\n            torques = joint_data['torques']\n\n            # Estimate static friction (intercept at zero velocity)\n            static_friction = np.mean(np.abs(torques[velocities == 0]))\n\n            # Estimate viscous friction (slope for non-zero velocities)\n            non_zero_vel = velocities != 0\n            viscous_coeff = np.mean(torques[non_zero_vel] / velocities[non_zero_vel])\n\n            friction_params[joint_idx] = {\n                'static': static_friction,\n                'viscous': abs(viscous_coeff)\n            }\n\n        return friction_params\n\n    def validate_identification(self):\n        \"\"\"Validate identified parameters with held-out data\"\"\"\n        # Use separate validation dataset\n        validation_data = self.get_validation_data()\n\n        total_error = 0\n        for data in validation_data:\n            # Simulate with identified parameters\n            sim_outputs = self.model.simulate(data['inputs'])\n\n            # Calculate validation error\n            error = np.mean(np.abs(sim_outputs - data['outputs']))\n            total_error += error\n\n        return total_error / len(validation_data)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-fitting-techniques",children:"Model Fitting Techniques"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, WhiteKernel\nimport joblib\n\nclass ModelRefiner:\n    def __init__(self):\n        self.correction_models = {}\n        self.residual_data = []\n\n    def learn_residual_models(self, sim_data, real_data):\n        """Learn correction models for simulation errors"""\n        for state_type in [\'positions\', \'velocities\', \'accelerations\']:\n            # Calculate residuals (real - simulation)\n            residuals = real_data[state_type] - sim_data[state_type]\n\n            # Use state and control inputs as features for correction\n            features = np.column_stack([\n                sim_data[\'positions\'],\n                sim_data[\'velocities\'],\n                sim_data[\'controls\']\n            ])\n\n            # Train Gaussian Process model to predict residuals\n            kernel = RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0)\n            gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6)\n\n            gp.fit(features, residuals)\n            self.correction_models[state_type] = gp\n\n    def apply_corrections(self, sim_state, control_input):\n        """Apply learned corrections to simulation"""\n        features = np.column_stack([\n            sim_state[\'positions\'],\n            sim_state[\'velocities\'],\n            control_input\n        ])\n\n        corrected_state = sim_state.copy()\n\n        for state_type in [\'positions\', \'velocities\', \'accelerations\']:\n            if state_type in self.correction_models:\n                # Predict and apply correction\n                correction = self.correction_models[state_type].predict(features)\n                corrected_state[state_type] += correction\n\n        return corrected_state\n\n    def online_adaptation(self, real_state, sim_state):\n        """Update correction models based on real-world observations"""\n        # Calculate current residual\n        residual = real_state - sim_state\n\n        # Update GP model with new data point\n        # (In practice, this would involve more sophisticated online learning)\n        pass\n\n    def save_models(self, filepath):\n        """Save learned correction models"""\n        joblib.dump(self.correction_models, filepath)\n\n    def load_models(self, filepath):\n        """Load learned correction models"""\n        self.correction_models = joblib.load(filepath)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"robust-control-design",children:"Robust Control Design"}),"\n",(0,i.jsx)(n.p,{children:"Designing controllers that are robust to model inaccuracies is crucial for sim-to-real transfer."}),"\n",(0,i.jsx)(n.h3,{id:"robust-pid-control",children:"Robust PID Control"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\n\nclass RobustPIDController:\n    def __init__(self, kp, ki, kd, robustness_margin=0.1):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.integral = 0\n        self.previous_error = 0\n        self.robustness_margin = robustness_margin\n\n        # Adaptive parameters\n        self.adaptive_enabled = True\n        self.param_history = {\'kp\': [], \'ki\': [], \'kd\': []}\n\n    def compute_control(self, error, dt):\n        """Compute robust PID control with anti-windup and noise filtering"""\n        # Apply low-pass filter to reduce noise effects\n        filtered_error = self._low_pass_filter(error)\n\n        # Proportional term\n        p_term = self.kp * filtered_error\n\n        # Integral term with anti-windup\n        self.integral += filtered_error * dt\n        # Limit integral to prevent windup\n        integral_limit = 1.0 / self.ki if self.ki != 0 else 1.0\n        self.integral = np.clip(self.integral, -integral_limit, integral_limit)\n        i_term = self.ki * self.integral\n\n        # Derivative term with noise filtering\n        derivative = (filtered_error - self.previous_error) / dt if dt > 0 else 0\n        d_term = self.kd * derivative\n\n        # Store for next iteration\n        self.previous_error = filtered_error\n\n        # Apply robustness margin to prevent aggressive control\n        control_output = p_term + i_term + d_term\n        control_output = np.clip(control_output,\n                                -self.robustness_margin,\n                                self.robustness_margin)\n\n        return control_output\n\n    def _low_pass_filter(self, signal, cutoff_freq=10.0):\n        """Apply low-pass filter to reduce noise"""\n        # Simple first-order low-pass filter\n        if not hasattr(self, \'filtered_signal\'):\n            self.filtered_signal = signal\n        else:\n            alpha = 1.0 / (1.0 + 2 * np.pi * cutoff_freq * 0.01)  # dt assumed to be 0.01\n            self.filtered_signal = alpha * signal + (1 - alpha) * self.filtered_signal\n\n        return self.filtered_signal\n\n    def adapt_parameters(self, tracking_error, control_effort):\n        """Adapt PID parameters based on performance"""\n        if not self.adaptive_enabled:\n            return\n\n        # Adjust parameters based on tracking performance\n        error_magnitude = np.abs(tracking_error)\n        effort_magnitude = np.abs(control_effort)\n\n        # If error is large, increase gains\n        if error_magnitude > 0.1:  # Threshold\n            self.kp *= 1.01\n            self.ki *= 1.01\n        # If control effort is excessive, decrease gains\n        elif effort_magnitude > 0.8:  # Threshold\n            self.kp *= 0.99\n            self.ki *= 0.99\n\n        # Store history for monitoring\n        self.param_history[\'kp\'].append(self.kp)\n        self.param_history[\'ki\'].append(self.ki)\n        self.param_history[\'kd\'].append(self.kd)\n\n        # Limit parameter values\n        self.kp = np.clip(self.kp, 0.1, 100.0)\n        self.ki = np.clip(self.ki, 0.01, 50.0)\n        self.kd = np.clip(self.kd, 0.01, 10.0)\n\nclass RobustTrajectoryController:\n    def __init__(self, robot_model, trajectory_generator):\n        self.robot = robot_model\n        self.trajectory_gen = trajectory_generator\n        self.pid_controllers = [RobustPIDController(10, 1, 0.1) for _ in range(robot_model.num_joints)]\n        self.disturbance_observer = DisturbanceObserver(robot_model)\n\n    def track_trajectory(self, current_state, target_trajectory, dt):\n        """Track trajectory with robust control"""\n        # Generate desired state from trajectory\n        desired_state = self.trajectory_gen.get_desired_state()\n\n        # Compute tracking errors\n        position_error = desired_state[\'positions\'] - current_state[\'positions\']\n        velocity_error = desired_state[\'velocities\'] - current_state[\'velocities\']\n\n        # Apply disturbance compensation\n        disturbance_estimate = self.disturbance_observer.estimate_disturbance(\n            current_state, desired_state\n        )\n\n        # Compute control with robust PID\n        control_commands = np.zeros(self.robot.num_joints)\n        for i in range(self.robot.num_joints):\n            tracking_error = position_error[i]\n            control_commands[i] = self.pid_controllers[i].compute_control(tracking_error, dt)\n\n            # Add disturbance compensation\n            control_commands[i] -= disturbance_estimate[i]\n\n            # Adapt parameters based on performance\n            self.pid_controllers[i].adapt_parameters(tracking_error, control_commands[i])\n\n        return control_commands\n'})}),"\n",(0,i.jsx)(n.h3,{id:"disturbance-observer",children:"Disturbance Observer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class DisturbanceObserver:\n    def __init__(self, robot_model, cutoff_freq=10.0):\n        self.model = robot_model\n        self.cutoff_freq = cutoff_freq\n        self.state_history = []\n        self.disturbance_estimate = np.zeros(robot_model.num_joints)\n        self.filter_state = np.zeros(robot_model.num_joints)\n\n    def estimate_disturbance(self, current_state, desired_state):\n        \"\"\"Estimate external disturbances using model prediction error\"\"\"\n        # Predict next state using model\n        model_prediction = self.model.predict_state(\n            current_state, desired_state['controls']\n        )\n\n        # Calculate prediction error (indicates disturbances)\n        prediction_error = current_state['positions'] - model_prediction['positions']\n\n        # Apply low-pass filter to estimate slowly-varying disturbances\n        alpha = 1.0 / (1.0 + 2 * np.pi * self.cutoff_freq * 0.01)  # Assuming dt = 0.01\n        self.disturbance_estimate = alpha * prediction_error + (1 - alpha) * self.disturbance_estimate\n\n        return self.disturbance_estimate\n"})}),"\n",(0,i.jsx)(n.h2,{id:"adaptive-control-techniques",children:"Adaptive Control Techniques"}),"\n",(0,i.jsx)(n.h3,{id:"model-reference-adaptive-control-mrac",children:"Model Reference Adaptive Control (MRAC)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ModelReferenceAdaptiveController:\n    def __init__(self, robot_model, reference_model, gamma=0.1):\n        self.robot_model = robot_model\n        self.ref_model = reference_model\n        self.gamma = gamma  # Adaptation rate\n\n        # Adaptive parameters\n        self.theta = np.zeros(robot_model.num_joints)  # Parameter estimates\n        self.P = np.eye(robot_model.num_joints) * 100  # Covariance matrix\n\n    def compute_control(self, current_state, reference_state, dt):\n        """Compute control using MRAC"""\n        # Tracking error\n        error = reference_state[\'positions\'] - current_state[\'positions\']\n        error_dot = reference_state[\'velocities\'] - current_state[\'velocities\']\n\n        # Reference model dynamics\n        ref_accel = self.ref_model.get_acceleration(reference_state)\n\n        # Control law: u = u_model + u_adaptive\n        # where u_model cancels known dynamics\n        # and u_adaptive handles uncertainties\n        model_control = self.robot_model.inverse_dynamics(\n            current_state[\'positions\'],\n            current_state[\'velocities\'],\n            ref_accel\n        )\n\n        # Adaptive control term\n        adaptive_control = self.theta * error\n\n        # Total control\n        control = model_control + adaptive_control\n\n        # Update parameter estimates\n        self._update_parameters(error, current_state, dt)\n\n        return control\n\n    def _update_parameters(self, error, state, dt):\n        """Update adaptive parameters using gradient descent"""\n        # Gradient of parameter estimation error\n        phi = self._regression_vector(state)\n\n        # Covariance update (recursive least squares)\n        K = self.P @ phi / (1 + phi.T @ self.P @ phi)\n        self.P = self.P - K @ phi.T @ self.P\n\n        # Parameter update\n        self.theta += self.gamma * K * error\n\nclass SelfTuningRegulator:\n    def __init__(self, robot_model, control_horizon=10):\n        self.model = robot_model\n        self.control_horizon = control_horizon\n        self.parameter_estimator = RecursiveLeastSquares()\n\n    def compute_optimal_control(self, current_state, reference_trajectory):\n        """Compute optimal control using online parameter estimation"""\n        # Estimate model parameters online\n        estimated_params = self.parameter_estimator.get_parameters()\n\n        # Update internal model\n        self.model.update_parameters(estimated_params)\n\n        # Solve optimal control problem over horizon\n        optimal_control = self._solve_mpc_problem(\n            current_state, reference_trajectory\n        )\n\n        return optimal_control\n\n    def _solve_mpc_problem(self, current_state, reference_trajectory):\n        """Solve Model Predictive Control problem"""\n        # Define cost function\n        def cost_function(controls):\n            total_cost = 0\n            state = current_state.copy()\n\n            for i in range(self.control_horizon):\n                # Apply control and simulate\n                state = self.model.predict_state(state, controls[i])\n\n                # Add tracking cost\n                tracking_error = reference_trajectory[i] - state[\'positions\']\n                total_cost += np.sum(tracking_error**2)\n\n                # Add control effort cost\n                total_cost += 0.01 * np.sum(controls[i]**2)\n\n            return total_cost\n\n        # Optimize control sequence\n        from scipy.optimize import minimize\n\n        initial_controls = np.zeros((self.control_horizon, self.model.num_joints))\n        result = minimize(cost_function, initial_controls.flatten())\n\n        optimal_controls = result.x.reshape((self.control_horizon, self.model.num_joints))\n\n        # Return first control in sequence\n        return optimal_controls[0]\n'})}),"\n",(0,i.jsx)(n.h2,{id:"transfer-learning-strategies",children:"Transfer Learning Strategies"}),"\n",(0,i.jsx)(n.h3,{id:"progressive-domain-transfer",children:"Progressive Domain Transfer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ProgressiveDomainTransfer:\n    def __init__(self, sim_env, real_env):\n        self.sim_env = sim_env\n        self.real_env = real_env\n        self.transfer_stage = 0\n        self.performance_thresholds = [0.6, 0.8, 0.9]  # Performance thresholds\n\n    def transfer_policy_progressively(self, policy):\n        """Transfer policy from simulation to reality progressively"""\n        while self.transfer_stage < len(self.performance_thresholds):\n            # Adjust simulation to be more realistic\n            self._adjust_simulation_fidelity()\n\n            # Train policy in adjusted simulation\n            policy = self._train_in_simulation(policy)\n\n            # Test on real robot\n            real_performance = self._test_on_real_robot(policy)\n\n            # Check if performance meets threshold\n            if real_performance >= self.performance_thresholds[self.transfer_stage]:\n                self.transfer_stage += 1\n                print(f"Transfer stage {self.transfer_stage} completed")\n            else:\n                # Continue training in current simulation fidelity\n                print(f"Performance {real_performance:.3f} below threshold, continuing training")\n\n        return policy\n\n    def _adjust_simulation_fidelity(self):\n        """Gradually reduce simulation fidelity to match reality"""\n        if self.transfer_stage == 0:\n            # High fidelity simulation\n            self.sim_env.set_physics_accuracy(\'high\')\n            self.sim_env.set_sensor_noise(\'low\')\n        elif self.transfer_stage == 1:\n            # Medium fidelity simulation\n            self.sim_env.set_physics_accuracy(\'medium\')\n            self.sim_env.set_sensor_noise(\'medium\')\n            # Add some actuator delays\n            self.sim_env.set_actuator_delay(0.01)\n        else:\n            # Low fidelity simulation (closer to real)\n            self.sim_env.set_physics_accuracy(\'low\')\n            self.sim_env.set_sensor_noise(\'high\')\n            self.sim_env.set_actuator_delay(0.02)\n            # Add environmental disturbances\n            self.sim_env.enable_disturbances(True)\n\n    def _train_in_simulation(self, policy):\n        """Train policy in current simulation environment"""\n        # Training loop\n        for episode in range(1000):  # Adjust as needed\n            state = self.sim_env.reset()\n            done = False\n\n            while not done:\n                action = policy.get_action(state)\n                next_state, reward, done, info = self.sim_env.step(action)\n                policy.update(state, action, reward, next_state)\n                state = next_state\n\n        return policy\n\n    def _test_on_real_robot(self, policy):\n        """Test policy on real robot and return performance metric"""\n        total_reward = 0\n        num_episodes = 10\n\n        for episode in range(num_episodes):\n            state = self.real_env.reset()\n            done = False\n            episode_reward = 0\n\n            while not done:\n                action = policy.get_action(state)\n                next_state, reward, done, info = self.real_env.step(action)\n                episode_reward += reward\n                state = next_state\n\n            total_reward += episode_reward\n\n        return total_reward / num_episodes\n'})}),"\n",(0,i.jsx)(n.h3,{id:"fine-tuning-on-real-data",children:"Fine-tuning on Real Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport numpy as np\n\nclass RealDataFineTuner:\n    def __init__(self, pre_trained_policy, real_data_buffer):\n        self.policy = pre_trained_policy\n        self.real_buffer = real_data_buffer\n        self.fine_tuning_enabled = True\n\n    def fine_tune_policy(self, learning_rate=1e-5, epochs=100):\n        """Fine-tune policy using real robot data"""\n        if not self.fine_tuning_enabled:\n            return\n\n        optimizer = torch.optim.Adam(\n            self.policy.parameters(),\n            lr=learning_rate,\n            weight_decay=1e-4\n        )\n\n        criterion = nn.MSELoss()\n\n        for epoch in range(epochs):\n            total_loss = 0\n            num_batches = 0\n\n            # Sample batches from real data buffer\n            for batch in self.real_buffer.sample_batches(batch_size=32):\n                states, actions, rewards, next_states = batch\n\n                # Forward pass\n                predicted_actions = self.policy(states)\n\n                # Calculate loss\n                loss = criterion(predicted_actions, actions)\n\n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n                num_batches += 1\n\n            avg_loss = total_loss / num_batches\n            print(f"Fine-tuning epoch {epoch}, avg loss: {avg_loss:.6f}")\n\n    def safe_fine_tuning(self, safety_margin=0.1):\n        """Fine-tune while maintaining safety constraints"""\n        # Collect initial performance baseline\n        initial_performance = self._evaluate_performance()\n\n        # Fine-tune with safety checks\n        for epoch in range(100):\n            # Perform one step of fine-tuning\n            self._single_fine_tuning_step()\n\n            # Check performance hasn\'t degraded beyond safety margin\n            current_performance = self._evaluate_performance()\n\n            if current_performance < initial_performance * (1 - safety_margin):\n                print("Performance degradation detected, stopping fine-tuning")\n                break\n\nclass ImitationLearningTransfer:\n    def __init__(self, expert_demonstrations, student_policy):\n        self.expert_data = expert_demonstrations\n        self.student_policy = student_policy\n\n    def behavioral_cloning_transfer(self):\n        """Transfer behavior using behavioral cloning"""\n        # Prepare dataset\n        states = torch.tensor(self.expert_data[\'states\'], dtype=torch.float32)\n        actions = torch.tensor(self.expert_data[\'actions\'], dtype=torch.float32)\n\n        # Train student policy to mimic expert\n        optimizer = torch.optim.Adam(self.student_policy.parameters(), lr=1e-4)\n        criterion = nn.MSELoss()\n\n        for epoch in range(1000):\n            optimizer.zero_grad()\n\n            # Forward pass\n            predicted_actions = self.student_policy(states)\n            loss = criterion(predicted_actions, actions)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            if epoch % 100 == 0:\n                print(f"BC epoch {epoch}, loss: {loss.item():.6f}")\n\n        return self.student_policy\n\n    def dagger_transfer(self, real_env, num_iterations=10):\n        """Transfer using Dataset Aggregation (DAgger)"""\n        for iteration in range(num_iterations):\n            # Collect data using current policy on real robot\n            real_data = self._collect_real_data(real_env, self.student_policy)\n\n            # Add to training set\n            self.expert_data.add_data(real_data)\n\n            # Retrain policy\n            self.student_policy = self.behavioral_cloning_transfer()\n\n        return self.student_policy\n'})}),"\n",(0,i.jsx)(n.h2,{id:"evaluation-and-validation",children:"Evaluation and Validation"}),"\n",(0,i.jsx)(n.h3,{id:"sim-to-real-performance-metrics",children:"Sim-to-Real Performance Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class TransferEvaluator:\n    def __init__(self, sim_env, real_env):\n        self.sim_env = sim_env\n        self.real_env = real_env\n        self.metrics = {}\n\n    def evaluate_transfer_performance(self, policy):\n        \"\"\"Evaluate sim-to-real transfer performance\"\"\"\n        # Test policy in simulation\n        sim_performance = self._evaluate_in_simulation(policy)\n\n        # Test policy on real robot\n        real_performance = self._evaluate_on_real_robot(policy)\n\n        # Calculate transfer ratio\n        transfer_ratio = real_performance / sim_performance if sim_performance != 0 else 0\n\n        # Calculate performance gap\n        performance_gap = sim_performance - real_performance\n\n        self.metrics = {\n            'sim_performance': sim_performance,\n            'real_performance': real_performance,\n            'transfer_ratio': transfer_ratio,\n            'performance_gap': performance_gap,\n            'success_rate': self._calculate_success_rate(policy)\n        }\n\n        return self.metrics\n\n    def _evaluate_in_simulation(self, policy):\n        \"\"\"Evaluate policy in simulation environment\"\"\"\n        total_reward = 0\n        num_episodes = 50\n\n        for _ in range(num_episodes):\n            state = self.sim_env.reset()\n            done = False\n            episode_reward = 0\n\n            while not done:\n                action = policy.get_action(state)\n                state, reward, done, _ = self.sim_env.step(action)\n                episode_reward += reward\n\n            total_reward += episode_reward\n\n        return total_reward / num_episodes\n\n    def _evaluate_on_real_robot(self, policy):\n        \"\"\"Evaluate policy on real robot\"\"\"\n        total_reward = 0\n        num_episodes = 10  # Fewer episodes on real robot\n\n        for _ in range(num_episodes):\n            state = self.real_env.reset()\n            done = False\n            episode_reward = 0\n\n            while not done:\n                action = policy.get_action(state)\n                state, reward, done, _ = self.real_env.step(action)\n                episode_reward += reward\n\n            total_reward += episode_reward\n\n        return total_reward / num_episodes\n\n    def _calculate_success_rate(self, policy):\n        \"\"\"Calculate success rate for specific tasks\"\"\"\n        success_count = 0\n        total_attempts = 10\n\n        for _ in range(total_attempts):\n            state = self.real_env.reset()\n            done = False\n            success = False\n\n            # Run episode and check for success condition\n            for _ in range(1000):  # Max steps\n                action = policy.get_action(state)\n                state, reward, done, info = self.real_env.step(action)\n\n                # Check success condition (example: reaching target)\n                if info.get('success', False):\n                    success = True\n                    break\n\n                if done:\n                    break\n\n            if success:\n                success_count += 1\n\n        return success_count / total_attempts\n\n    def analyze_failure_modes(self, policy):\n        \"\"\"Analyze common failure modes in sim-to-real transfer\"\"\"\n        failure_modes = {\n            'falling': 0,\n            'joint_limits': 0,\n            'tracking_error': 0,\n            'instability': 0\n        }\n\n        for _ in range(20):  # Run multiple trials\n            state = self.real_env.reset()\n            done = False\n            initial_height = state['base_position'][2]\n\n            while not done:\n                action = policy.get_action(state)\n                state, reward, done, info = self.real_env.step(action)\n\n                # Check for various failure modes\n                current_height = state['base_position'][2]\n\n                # Falling check\n                if current_height < 0.3:  # Fell down\n                    failure_modes['falling'] += 1\n                    break\n\n                # Joint limit violation\n                if np.any(np.abs(state['joint_positions']) > 3.0):  # Example limit\n                    failure_modes['joint_limits'] += 1\n\n                # Tracking error too large\n                if info.get('tracking_error', 0) > 0.5:\n                    failure_modes['tracking_error'] += 1\n\n                # Instability (high joint velocities)\n                if np.any(np.abs(state['joint_velocities']) > 10.0):\n                    failure_modes['instability'] += 1\n\n        return failure_modes\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-sim-to-real-transfer",children:"Best Practices for Sim-to-Real Transfer"}),"\n",(0,i.jsx)(n.h3,{id:"pre-transfer-validation",children:"Pre-Transfer Validation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Validate simulation models against real robot behavior"}),"\n",(0,i.jsx)(n.li,{children:"Test controllers in simulation with realistic noise and delays"}),"\n",(0,i.jsx)(n.li,{children:"Use multiple simulation environments to test robustness"}),"\n",(0,i.jsx)(n.li,{children:"Implement safety checks before real robot deployment"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"safety-considerations",children:"Safety Considerations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Implement safety limits and emergency stops"}),"\n",(0,i.jsx)(n.li,{children:"Use position and velocity bounds"}),"\n",(0,i.jsx)(n.li,{children:"Monitor for unexpected behaviors"}),"\n",(0,i.jsx)(n.li,{children:"Have manual override capability"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"gradual-deployment",children:"Gradual Deployment"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Start with simple behaviors before complex ones"}),"\n",(0,i.jsx)(n.li,{children:"Use progressive domain transfer techniques"}),"\n",(0,i.jsx)(n.li,{children:"Monitor performance metrics continuously"}),"\n",(0,i.jsx)(n.li,{children:"Maintain ability to revert to safe behaviors"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,i.jsx)(n.h3,{id:"poor-transfer-performance",children:"Poor Transfer Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def diagnose_transfer_issues(policy, evaluator):\n    """Diagnose common sim-to-real transfer issues"""\n    metrics = evaluator.metrics\n\n    issues = []\n\n    if metrics[\'transfer_ratio\'] < 0.5:\n        issues.append("Poor transfer ratio - reality gap too large")\n\n    if metrics[\'performance_gap\'] > 100:\n        issues.append("Large performance gap between sim and real")\n\n    if metrics[\'success_rate\'] < 0.3:\n        issues.append("Low success rate on real robot")\n\n    return issues\n'})}),"\n",(0,i.jsx)(n.h3,{id:"instability-on-real-robot",children:"Instability on Real Robot"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reduce control gains"}),"\n",(0,i.jsx)(n.li,{children:"Add more conservative safety limits"}),"\n",(0,i.jsx)(n.li,{children:"Increase sensor noise in simulation"}),"\n",(0,i.jsx)(n.li,{children:"Use more robust control techniques"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"Simulation-to-real transfer remains one of the most challenging aspects of humanoid robotics. Success requires careful attention to modeling accuracy, robust control design, and systematic validation. Domain randomization, system identification, and progressive transfer techniques can significantly improve transfer success rates. The key is to systematically address the reality gap through modeling, control design, and validation techniques that bridge the simulation and real worlds."}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Implement domain randomization for a humanoid walking controller"}),"\n",(0,i.jsx)(n.li,{children:"Design a disturbance observer for a simulated humanoid robot"}),"\n",(0,i.jsx)(n.li,{children:"Evaluate the transfer performance of a learned policy from simulation to a real robot model"}),"\n",(0,i.jsx)(n.li,{children:"Implement a progressive domain transfer strategy for humanoid locomotion"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsx)(n.p,{children:'[1] J. Tan et al., "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots," RSS, 2018.'}),"\n",(0,i.jsx)(n.p,{children:'[2] X. B. Peng et al., "Sim-to-Real Transfer of Robotic Control with Dynamics Randomization," ICRA, 2018.'}),"\n",(0,i.jsx)(n.p,{children:'[3] T. P. Lillicrap et al., "Continuous Control with Deep Reinforcement Learning," ICLR, 2016.'}),"\n",(0,i.jsx)(n.p,{children:'[4] M. Andrychowicz et al., "Hindsight Experience Replay," NIPS, 2017.'})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);